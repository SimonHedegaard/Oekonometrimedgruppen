---
title: "Exam 1 - Viktor"
author: "Viktor Damm"
date: "2024-05-02"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(sandwich)
library(foreign)
library(texreg)
```

```{r}
data1 <- read.csv("~/Desktop/Oecon/4. semester/Økonometri/Econ Exam/data1.csv")
salary<-data1$salary
educ<-data1$educ
salbegin<-data1$salbegin
male<-data1$male
minority<-data1$minority
```

log(salary) = β0 + β1educ + β2log(salbegin) + β3male + β4minority + u

#1. Estimer modellen vha. OLS. Kommenter på outputtet og fortolk resultaterne.

First of all, we are going the estimate the model using a simple OLS regression in R. This is done with the following code:
```{r}
reg=lm(log(salary)~educ+log(salbegin)+male+minority)
summary(reg)
```
First, we are going to comment of the estimates: 

We can see that if education increases by one unit, then salary increases by 2,3 pct, holding every other parameter fixed. Furthermore, we can see that the estimate is significant down to a 0.1 pct. significance level. Next, we can see that a 1 pct. increase in beginning salaly leads to a 0,82 pct. increase in salary. This estimate is significant down to a 0.1 pct. significance level, as well. We have also included two dummy variables in our regression, male and minority. The estimate on male is 0.04, meaning that a male gets 4% higher salary than females (which is the reference group) holding everything else fixed. The estimate on minority is -0.04, which means that a minority gets 4% lower salary than non-minorities (which is the reference group) holding everything else fixed. Both of these estiamtes are significant down to a 5 pct. significance level. 

We can observe that all variables have the expected sign on the estimates. Further, the R-squared and adjusted R-squared are both around 80 pct, meaning that the model fits 80% of the data. The R-square indicates how well the model fits the data, meaning that it is a meausre of how good the model is. The adjusted R-sqaure also takes the number of independent variables into account. The F-statistic in the model is 481,3 with a p-value of 2.2e-16, meaning that the varibles are jointly significant. 

#Opgave 2. - Udfør grafisk modelkontrol

We make 4 different graphic model control: 

```{r}
plot(reg, 1)
```
-The dots are equally sread around a horizontal line, indicating, that we dont have any non-linear relationship 
- This is a sign of well specified model

```{r}
plot(reg, 2)
```
- This plot shows, if the residuals are normally distributed
- If they fit nicely around the dottet line, then they are normally distributed 
- Verifies MLR 6
- You could also plot a histogram of the residuals!

```{r}
plot(reg, 3)
```
- This one checks for homoskedasticity
- -The dots are equally sread around a horizontal line, indicating, that we have homoskedasticity
- They are randomly spread and does not increase with the fitted values 

```{r}
plot(reg, 5)
```
- THis one check, if we have any outliers of major impact
_ Cook's distance lines are not even present, meaning that there are no outliers of impact. 

#3. Test for heteroskedasticitet vha. Breusch-Pagan-testet og specialudgaven af White-testet.

```{r}
residuals <- resid(reg)
residuals_squared <- residuals^2
```

```{r}
res_mod <- lm(residuals_squared ~ educ + log(salbegin) + male + minority)
summary(res_mod)
```

```{r}
multiple_r_squared <- 0.02923
n <- nrow(data1)
lm_test <- multiple_r_squared*n
lm_test
```

```{r}
p_value_lmtest <- 1-pchisq(lm_test,4)
p_value_lmtest
```

```{r}
library(lmtest)
bptest(reg)
```
- We reject H0, so there is Heteroskedasticity
- We cannot use the graphical model control

We now use the White-Test: 

```{r}
y_hat <- reg$fitted.values
y_hatsquared <- reg$fitted.values^2
white_test <- lm(residuals_squared ~ y_hat + y_hatsquared)
summary(white_test)
```
- We reject H0 again!

#4. Beregn robuste standardfejl for modellen og sammenlign med resultaterne i spørgsmål 1.

- Vi bruger R til at udregne dem, men vi skal også have formlen med, så dden kan forklares: 

```{r}
reg_robust <- coeftest(reg, vcov = vcovHC(reg, type = "HC0"))
screenreg(list(OLS =reg, OLS_robust_se =reg_robust), digits =4)
```
- Here we can compare our standard errors with our robust standard errors
- Not so big a differene
- The results does not change
- Heterosekdasticity is not very strong in this example


#5. Test hypotesen H0 : β2 = 1 mod alternativet H1 : β2 ̸= 1.
```{r}
t_stat<-(0.82180-1)/0.0374
t_stat
c<-qt(0.05, n-1)
c
p_value<- pt(t_stat, n-1)
p_value
```
- We reject the Null Hypothesis
- Beta_2 is statistically different from 1
- We reject at a 5 pct. significance level 

#6. Test hypotesen H0 : β3 = β4 = 0.

```{r}
reg_restricted <- lm(log(salary)~educ+log(salbegin))
r2_un <- summary(reg)$r.squared
r2_r <- summary(reg_restricted)$r.squared
df <- nrow(data1)-4-1
```

```{r}
#Here we are obtaining our F-statistic
f_stat <- ((r2_un - r2_r)/2)/((1 - r2_un)/df)
f_critical <- qf(0.95, 2, df)
p_value_f <- 1-pf(f_stat, 2, df)
```
- We reject our Null hypothesis 
- Beta_3 and beta_4 are statistically different from 0
- We cxan also test it with a function in R:

```{r}
library(foreign)
library(car)
myh0 <- c("male=0", "minority=0")
linearHypothesis(reg, myh0)
```

#7. Estimer modellen vha. FGLS og kommenter på resultaterne

```{r}
logu_2 <- log(resid(reg)^2) #Obtain residuals from the original regression - We square them - And we log them
```

```{r}
varreg <- lm(logu_2 ~ educ + log(salbegin) + male + minority) #We run a regression on the log_squared_residuals
```

```{r}
w <- exp(fitted(varreg)) #Obtaining the weights
```

```{r}
fgls <- lm(log(salary)~educ+log(salbegin)+male+minority, weight=1/w)
screenreg(list(OLS = reg, FGLS = fgls), digits = 4)
```
- No differencs between the estimates, standard errors or significance of the estimates 

#8. Har FGLS estimationen taget højde for al heteroskedasticiteten?

```{r}
fgls_robust <- coeftest(fgls, vcov = vcovHC(fgls, type = "HC0"))
screenreg(list(OLS = reg, FGLS = fgls, FGLS_robust = fgls_robust), digits = 4)
```
- Here we have obtained robust standard errors for the FGLS 