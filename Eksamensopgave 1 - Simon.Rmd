---
title: "Eksamensopgave 1"
output: html_document
date: "2024-03-18"
---

```{r}
data1 <- read.csv("~/Desktop/Økonometri 4. semester/Økonometrimedgruppen/data1.csv")
View(data1)
salary<-data1$salary
educ<-data1$educ
salbegin<-data1$salbegin
male<-data1$male
minority<-data1$minority
```

log(salary) = β0 + β1educ + β2log(salbegin) + β3male + β4minority + u





1. Estimer modellen vha. OLS. Kommenter på outputtet og fortolk resultaterne.
```{r}
reg=lm(log(salary)~educ+log(salbegin)+male+minority)
summary(reg)
```
We can see that salary increases the most when the beginning salary increases with 1% holding everything else fixed.
We can also see that a male gets 4% higher salary than females holding everything else fixed. All results are significant. Adjusted R squared is fine.
We fail to reject H0 meaning that the variables are jointly significant. All variables have signs of what we should expect.


2. Udfør grafisk modelkontrol.
```{r}
plot(reg,1) #Jo fladere rød linje jo mere er modellen non linear
```
It seems that there is no need for including non linear variables


```{r}
plot(reg,2) #Igen en lineær sammenhæng tyder på at der er en normal fordeling
residuals<-resid(reg)
hist(residuals)#Man kan også lave histogrammer over error terms og se om de er normally distributed
library(tseries)
jarque.bera.test(reg$residuals)
shapiro.test(reg$residuals)
```
It seems that the residuals are normally distributed this also suggest that MLR5 and MLR4 are correct so that MLR6 is true. But if we chech for normallity in the residuals the result is that the residuals are not nornamlly distributed. 



```{r}
plot(reg,3) #bliver residualerne mere spredt ud fra den røde linje tyder det på at der ikke er homoskedacity
```
Residualerne er pænt fordelt om den røde linje således at der er homoskedacity


```{r}
plot(reg,5) #identificere om der er outliers som har betydning for resultatet
```
No problem with outliers here - we can not see the cooks distance lines


#3. Test for heteroskedasticitet vha. Breusch-Pagan-testet og specialudgaven af White-testet.

LM test:
```{r}
r2<-residuals^2

res_mod<-lm(r2~educ+log(salbegin)+male+minority)
summary(res_mod)

```

```{r}
lm<-0.02923*nrow(data1)
lm

p_val<-1-pchisq(lm,4)
p_val

```

```{r}
library(lmtest)
bptest(reg)
```

White test:
```{r}
y_hat<-fitted(reg)
y_hat_sq<-y_hat^2
```

```{r}
white_test<-lm(r2~y_hat+y_hat_sq)
summary(white_test)
```
Again we reject H0 meaning that the model contains hetroskedaticity


4. Beregn robuste standardfejl for modellen og sammenlign med resultaterne i spørgsmål 1.

$$
\text{Var}(\hat{\beta}_j) = \frac{\sum_{i=1}^{n} \hat{r}_{ij}^2 \cdot \hat{u}_i^2}{(\text{SSR}_j)^2}
$$



```{r}
library(texreg)
library(lmtest)
library(sandwich)
library(foreign)
library(textreg)
library(zoo)
modela <- reg
modelb <- coeftest(modela, vcov = vcovHC(modela, type = "HC0"))
screenreg(list(OLS = modela, OLS_robust_se = modelb), digits = 4)
```
Ovenstående udregner korrekte se når der er hetroskedacity - men de ændrer sig ikke ret meget.
Der er dermed ikke stærk hetro.


5. Test hypotesen H0 : β2 = 1 mod alternativet H1 : β2 ̸= 1.
```{r}
t_stat<-(0.82180-1)/0.0374
c<-qt(0.05,nrow(data1)-1)
p_val<-pt(t_stat,nrow(data1)-1)
p_val
```

We reject our null hypothesis meaning that β2 is not equal to 1, meaning that is statistical β2 ̸=1.

6. TesthypotesenH0 :β3 =β4 =0.
```{r}
ureg<-reg
rreg<-lm(log(salary)~educ+log(salbegin))
r2_ureg<-summary(ureg)$r.squared
r2_rreg<-summary(rreg)$r.squared

df<-ureg$df.residual #n-k-1
df

F<-((r2_ureg-r2_rreg)/2/((1-r2_ureg)/df)) #F test (2 er de antal variable vi fjerne i restricted)
F

qt(0.95, df) #kritiske værdi

1-pf(F, 2, df) #p-værdi

```
We use a F statistic because it is jointly measure.
We reject H0 meaning that Beta 3 and Beta 4 are statisticaly different
The p value is below our significance level of 5%, and our F statistic is greater than are critical value. 

We calculate this by a function in R as well.
```{r}
library(foreign)
library(car)
myh0 <- c("male=0", "minority=0")
linearHypothesis(reg, myh0)
```
Results are the same.


7. Estimer modellen vha. FGLS og kommenter på resultaterne.

Hvis man ikke ved hvilke variable som forsager heteroskedasticity kan FGLS anvendes
```{r}
logu2<-log(resid(reg)^2)
varreg<-lm(logu2~educ+log(salbegin)+male+minority)
w<-exp(fitted(varreg))


FGLS<-lm(log(salary)~educ+log(salbegin)+male+minority, weight=1/w)


library(texreg)
library(lmtest)
library(sandwich)
library(foreign)
library(textreg)
library(zoo)
screenreg(list(OLS = reg, FGLS = FGLS), digits = 4)

```
No variables changes much, meaning that we cannot be sure that we have corrected for hetro.



8. Har FGLS estimationen taget højde for al heteroskedasticiteten?

No it does not seem so and that is why we test for robust standard error on our FGLS model. 

```{r}
FGLS_robust<-coeftest(FGLS, vcov = vcovHC(FGLS, type = "HC0"))
screenreg(list(OLS = reg, FGLS = FGLS, FGLS_robust=FGLS_robust), digits = 4)
```
Results are almost the same, meaning that the model is not misspecified and there is only a small amount of hetroskedicity in the model.
HVORFOR ER R^2 ikke med i FGLS_robust???






